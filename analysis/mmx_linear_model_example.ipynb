{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHwiHTunM3IG",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "source": [
        "# Marketing Mix Models \n",
        "\n",
        "## The Basics\n",
        "\n",
        "\n",
        "Marketing Mix Modeling (MMM or MMX) is a statistical analysis technique used to evaluate the impact of a company's marketing activities on sales (or any variable that wants to be measured). It relies in analysing historical data and typically fitting a model in which sales acts as a dependent variable.\n",
        "\n",
        "MMM helps businesses understand the effectiveness of different marketing channels (such as TV, online ads, promotions, and pricing) and how they interact with each other. This insight allows companies to allocate their marketing budgets more efficiently, optimize their marketing strategies. MMM is particularly useful because it quantifies the return on investment (ROI) of marketing expenditures, enabling data-driven decision-making.\n",
        "\n",
        "It's a highly demanded skill that can be applied in virtually, any industry. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Objective of this Notebook \n",
        "\n",
        "This notebook serves as a guide on how to build MM models in order to obtain contributions of the different channels (touchpoints) on product sales. This toy example includes relevant feature transformations as adstock (decay), seasonality, saturation, lags, etc. \n",
        "\n",
        "Likewise, it has been built with toy data which mimics real-life scenarios, but is not a full picture of the marketing spends a real product has during a year.\n",
        "\n",
        "The basic application of these type of models uses a traditional linear model, however, it does have a few limitations that will be explored across the Notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Hh_rnfspT4t"
      },
      "source": [
        "## 1. Imports and setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sb5V0LWfWI_k"
      },
      "outputs": [],
      "source": [
        "# Imports.\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import optuna\n",
        "import plotly.express as px\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import mmx.utils as utils\n",
        "\n",
        "from mmx.linear import AdstockHyperTuning, add_adstock_to_pdf, sales_from, create_stack_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set up \n",
        "\n",
        "# Configuration for viz and verbosity.\n",
        "plt.rcParams[\"figure.figsize\"] = (20, 8)\n",
        "\n",
        "# Path were the input file is stored.\n",
        "data_path = \"../data/cough_and_cold_sales.csv\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aa_hhZj2GluZ"
      },
      "source": [
        "## 2. EDA and basic transformations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wShwfASJqTTe"
      },
      "source": [
        "Here we have synthetic weekly data of the sales of an off the counter **(OTC) cough and cold medicine** in a particular country. Along with the sales data, we have marketing spends for different channels that are typically relevant in the pharma industry. In this simple toy example we have a normalized monetary spend for tv, social media, medical crongresses, and trade (expenditure related to in-pharmacy display). We also have two external variables, the `stringency_index` which is related to the severness of COVID restrictions in this country, and the `flu_index` which is a variable monitored by the World Health Organization to track the intensity of the flu season in a particular region.  \n",
        "\n",
        "Our objective is to determine the ROI of each of our mtk channels, to enable data-drive decision making for allocating our future marketing budget. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define channels to use.\n",
        "CHANNELS: list[str] = ['tv', 'social_media', 'congress', 'trade']\n",
        "EXT_VARS: list[str] = ['flu_index', 'stringency_index'] \n",
        "# Define target variable.\n",
        "TARGET = 'sales'\n",
        "# Define weeks for testing period.\n",
        "TEST_SIZE = 8\n",
        "# Seed for reproducibility\n",
        "SEED = 123456"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load data\n",
        "df = pd.read_csv(data_path, sep= \";\", parse_dates=[\"date\"])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# set date as index as it will make plotting easier\n",
        "df.set_index(\"date\", inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot the target var and its Outliers\n",
        "outlier_index = utils.plot_outliers_signal(\n",
        "    df[TARGET], threshold=2\n",
        ")\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We have an evident abnormal event that happened in 2020 and 2021 that collapsed the sales. There's also a high spike in March 2020. This is of course, due to the pandemic, where there was a high \"panic buying\" spike, and later, a heavy drop in sales. \n",
        "\n",
        "What to do here?\n",
        "\n",
        "Many people decide to leave out the pandemic years. However, the effects of COVID could still be felt up until early 2022, which leaves us with very little data for fitting our model. What's best depends on the use case, however, for this example, let's add a flag that resembles the effects of the pandemic."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Adding a Covid flag\n",
        "df['covid_flag'] = utils.add_flag(\n",
        "    df,\n",
        "    outlier_index.min(),\n",
        "    outlier_index.max()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.head(2) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Interactive plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot it\n",
        "px.line(df.sales)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# PLot channel spend for month\n",
        "fig = px.bar(\n",
        "    df, \n",
        "    x=df.index, \n",
        "    y=CHANNELS, \n",
        "    title=\"Channel Spend per Date\"\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSo-JtkFp-Ue"
      },
      "source": [
        "## 3. Adstock modeling."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GqTdpENqaXI"
      },
      "source": [
        "In this section we add (i) carry over and (ii) saturation effects.\n",
        "\n",
        "We want to model the relationship of the different investment channels using a linear regression, however we want to take into account the [decay effect](https://en.wikipedia.org/wiki/Advertising_adstock#Advertising_lag:_decay_effect) and the [law of diminishing returns](https://en.wikipedia.org/wiki/Advertising_adstock#Campaign_carry-over).\n",
        "\n",
        "---\n",
        "For this, instead of working directly with spend per channel, we apply different transformations to them\n",
        "\n",
        "> 1. For carry over $c_{t}$, we apply the following transformation.\n",
        "$$c_{t} = x_{t} + \\sum_{j=1}^{n} \\lambda^{t}  x_{t-j}$$\n",
        ">\n",
        "> Where $x_{t}$ is the investment in the channel for the $t$ period, $n$ represents the amount of periods to look back and $\\lambda$ represents the strength of the decay factor. This means that investments made in time $t$ will have still an impact of the following weeks, and this effect will decay over time. Both $n$ and $\\lambda$ will be parameters of the function.\n",
        "><br/>\n",
        "><br/>\n",
        ">2. For the saturation effect $s_{t}$, the following transformation is applied.\n",
        ">\n",
        ">$$s_{t} =1 -  e^{-\\alpha x_{t}} $$\n",
        ">\n",
        "> In this case, $\\alpha$ will be a parameter to input.\n",
        "\n",
        "<br/>\n",
        "\n",
        "In consequence, instead of modeling sales as a function of investment per channel, we fit a regression to the transformations described previously. The question now is which values should we use for **$n$, $\\lambda$ and $\\alpha$**? We can think of them as *hyperparameters of our model*. And then perform a *numerical optimization* to find values that minimize the mean squared error (or any metric of our interest) of the model.\n",
        "<br/>\n",
        "\n",
        "\n",
        "Lastly, data presents a heavy seasonality, one hot encoded variables were added for every month in the year.\n",
        "\n",
        "---\n",
        "\n",
        "For a complete explanation of the methods used in here, we refer the reader to page *154/510* of [Introduction to Algorithmic Marketing](https://algorithmicweb.files.wordpress.com/2018/07/algorithmic-marketing-ai-for-marketing-operations-r1-7g.pdf).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgp2qYycKSbL"
      },
      "source": [
        "## 4. Fit the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKjQa9oo9jqO"
      },
      "source": [
        "### Tune hyperparameters\n",
        "\n",
        "- We use optuna for hyperparameter tuning, but other libraries like `scipy.minimize` or `sklearn` should work as well.\n",
        "- For every channel, we have three ($\\alpha$, $n$ and $\\lambda$) hyperparameters to tune.\n",
        "- We work with a traditional linear regression. -> prone to overfitting!!\n",
        "- We aim to minimize *MSE*.\n",
        "- We repeat 1 000 trials for the optimization, caution! can take some time. Feel free to change `n_trials=100` to speed things up.\n",
        "- We split the dataset in train and test. Since we are working with time series we work with consecutives chunks of data.\n",
        "- To do the optimization we use the `AdstockHyperTuning` class defined under `mmx.linear`. This class will optimize on alpha, decay and lag per each of the media channels. The best combination of them will be selected based on the lower *MSE*. \n",
        "- For the optimization, we need to pass a hyperparamater space, we do this with the `PARAMS_DICT` dictionary defined below. Here we pass the name of the parameter, a lower bound, an upper bound and whether we are expecting a float or an integer. For alpha and decay, we expect a float value, whilst lag should be an int."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# see description above.\n",
        "PARAMS_DICT: dict = {  # channel: (lower_bound, upper_bound, type)\n",
        "        \"alpha_tv\": (0, 0.1, \"float\"),  # floats\n",
        "        'decay_tv': (0, 0.5, \"float\"),  # floats\n",
        "        'lag_tv': (0, 6, \"int\"),  # int\n",
        "        'alpha_social_media': (0, 0.1, \"float\"),\n",
        "        'decay_social_media': (0, 0.5, \"float\"),\n",
        "        'lag_social_media': (0, 6, \"int\"),\n",
        "        'alpha_congress': (0, 0.1, \"float\"),\n",
        "        'decay_congress': (0, 0.5, \"float\"),\n",
        "        'lag_congress':  (0, 6, \"int\"),\n",
        "        'alpha_trade': (0, 0.1, \"float\"),\n",
        "        'decay_trade': (0, 0.5, \"float\"),\n",
        "        'lag_trade': (0, 6, \"int\")\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split data for train test.\n",
        "df_train = df.iloc[: -TEST_SIZE, :]\n",
        "df_test = df.iloc[-TEST_SIZE:, :]\n",
        "\n",
        "# Define features and target variable.\n",
        "features = [\n",
        "    c for c in list(df.columns) if 'flag' in c or 'index' in c\n",
        "] + [f'adstock_{c}' for c in CHANNELS]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "adstock_hypertuning = AdstockHyperTuning(\n",
        "    df=df_train,\n",
        "    hyperparameters=PARAMS_DICT,\n",
        "    features=features,\n",
        "    media_channels=CHANNELS,\n",
        "    target=TARGET,\n",
        "    n_trials=1_000,\n",
        ")\n",
        "\n",
        "tuned_params = adstock_hypertuning.hyperparam_tuning()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXZljqlCLnAO"
      },
      "source": [
        "### Run final model.\n",
        "With tuned hyperparameters, we train the final model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check optimized params.\n",
        "tuned_params.best_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0_J5daSq5BM",
        "outputId": "b9f7560c-e10d-41eb-f579-deb65efb9fa9"
      },
      "outputs": [],
      "source": [
        "# Best set of hyperparameters.\n",
        "hyperparameters = tuned_params.best_params\n",
        "\n",
        "# We replicate adstock transformation, train test splitting and model fitting. \n",
        "# Add adstock columns. \n",
        "df_adstock_train  = add_adstock_to_pdf(df_train, hyperparameters, CHANNELS) \n",
        "df_adstock_test = add_adstock_to_pdf(df_test, hyperparameters, CHANNELS)\n",
        "\n",
        "# Define train and test data.\n",
        "X_train, y_train = df_adstock_train[features], df_adstock_train[TARGET]\n",
        "X_test, y_test = df_adstock_test[features], df_adstock_test[TARGET]\n",
        "\n",
        "\n",
        "adstock_hypertuning.model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hSppHJmM62O"
      },
      "source": [
        "## 5. Model performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "bKt9OphHrK19",
        "outputId": "e627137b-2dbc-4db5-a25e-4377f87a13f8"
      },
      "outputs": [],
      "source": [
        "# Line chart for performance.\n",
        "\n",
        "y_train.index = df_train.index  # adding index back for convenience\n",
        "\n",
        "# Plot it\n",
        "actual_vs_pred = pd.DataFrame(\n",
        "    {\n",
        "        \"actual\": y_train,\n",
        "        \"pred\": adstock_hypertuning.model.predict(X_train),\n",
        "       \n",
        "    },\n",
        "    index=df_train.index\n",
        ")\n",
        "actual_vs_pred.plot(title=\"Actual vs prediction\")\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print(\"Training Performance\")\n",
        "utils.performance_metrics(y_train, adstock_hypertuning.model.predict(X_train))\n",
        "\n",
        "print(\"Test Performance\")\n",
        "utils.performance_metrics(y_test, adstock_hypertuning.model.predict(X_test))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WDHCLldNktY"
      },
      "source": [
        "## 6. Channel contribution.\n",
        "\n",
        "Now with a fitted model, we can estimate the contribution of each channel. This tipically answers to the question: How much of a sales uplift (incremental sales) are attributed to the investments in a given channel. \n",
        "\n",
        "With this information, if we know how incremental sales we are getting, and how much a channel cost, we can then calculate the channel's ROI (return of investment)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btC6qdJdPeiw"
      },
      "source": [
        "We observe the marginal channel contribution and the return on investment per channel.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFqLZGV1hmLe",
        "outputId": "3bb917ac-bdcb-4e34-f162-7dd7c3798127"
      },
      "outputs": [],
      "source": [
        "\n",
        "# base sales takes into account the intercept plus monthly effects.\n",
        "base = (\n",
        "    sum(\n",
        "        [\n",
        "            adstock_hypertuning.model.coef_[\n",
        "                features.index(c)\n",
        "            ] * X_train.iloc[:, features.index(c)]\n",
        "            for c in features if 'adstock' not in c\n",
        "        ]\n",
        "    )\n",
        "      + [adstock_hypertuning.model.intercept_] * len(df_train.index))\n",
        "\n",
        "# Computation of contribution S = B + b1*C1 + b2*C2 \n",
        "# Cnt_2 = (B+B1*C1+B2*C2) - (B+B1*C1) = B2*C2 \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create contribution plot\n",
        "plot_df = create_stack_df(X_train, features, adstock_hypertuning.model)\n",
        "# re adding base. \n",
        "base.name = \"base\"\n",
        "plot_df = pd.concat([base, plot_df], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "px.area(\n",
        "    plot_df,\n",
        "    title=\"Contribution Painting\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Compute ROI for every channel.\n",
        "for c in features:\n",
        "    if 'index' not in c and 'flag' not in c:\n",
        "        channel_share = np.round(\n",
        "            sum(\n",
        "                sales_from(c, features, adstock_hypertuning.model, X_train)) / \n",
        "            sum(adstock_hypertuning.model.predict(X_train)\n",
        "            ), \n",
        "        2)\n",
        "        channel_roi = np.round(\n",
        "            sum(\n",
        "                sales_from(\n",
        "                    c, features, adstock_hypertuning.model, X_train)) \n",
        "            / sum(df_adstock_train[c.replace('adstock_', '')]\n",
        "            )\n",
        "        ,2)\n",
        "        print(f'For {c}: share of total sales is {channel_share} and ROI is {channel_roi}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "px.bar(\n",
        "        y=adstock_hypertuning.model.coef_,\n",
        "        x=X_train.columns,\n",
        "        title='Contribution bar plot',\n",
        "        labels={\n",
        "            \"x\": \"Feature\",\n",
        "            \"y\": \"Contribution\"\n",
        "        }\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Discussion \n",
        "\n",
        "- If there are some channel contributions negative? Does this make sense from a business POV? \n",
        "- What about seasonality? Shall we consider it?\n",
        "- Would it be worth it to use another type of model, for example tree-based algorithms? or another type of linear model like Ridge?\n",
        "- What recommendations would you give to business with these results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next steps. \n",
        "\n",
        "This analysis is powerful, but we can aim to do better. The state-of-the-art in Marketing Mix Models is using Bayesian Statistics to properly capture the attributions of each feature. You can see an example in the [`mmx_bayesian_model_example`](mmx_bayesian_model_example.ipynb) notebook.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "iHwiHTunM3IG",
        "6Hh_rnfspT4t",
        "J_xqhVxApn4H",
        "Aa_hhZj2GluZ",
        "HSo-JtkFp-Ue",
        "MKjQa9oo9jqO",
        "iXZljqlCLnAO",
        "1hSppHJmM62O",
        "9WDHCLldNktY",
        "CJsR0BD2n5-D",
        "SqrY5dZSpJYP"
      ],
      "name": "Juan Prida: Marketing Mix Model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
